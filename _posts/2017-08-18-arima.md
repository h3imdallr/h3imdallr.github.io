---
layout:     post
published: True
title:      "Time Series Forecasting with ARIMA"
description:   "ì‹œê³„ì—´ ì˜ˆì¸¡ê¸°ë²•"
date:   2017-08-19 00:00:00
author:     "Josh Yongmin Jung"
tags: [data_science, time_series]
image: "/figures-h3imdallr/20161123-header-anomaly.jpg"
comments: false
share: false
---


# Time Series Forecasting

**scope**:
- ì‹œê°„ì— ëŒ€í•œ í•¨ìˆ˜, ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ì— ì£¼ì•ˆ,  ì¸ê³¼ ê´€ê³„X
- Data Wrangling for time-series in Python
- self projecting(o), cause and effect(X)
- uni-variate(o), multi-variate(x)
- Time-series Basics; seasonality, trend, residual, statrionary/non-stationary process
- Time-series forecasting using ARIMA (Box Jenkins Approach, ACF, PACF)

**requirements**:
- python 2.7 or 3
- statsmodel 0.8.0   
(**anaconda user** -> `conda install -c taugspurger statsmodels=0.8.0` ì°¸ê³ : https://anaconda.org/search?q=statsmodels%20   
// **pip user** -> `pip install statsmodels==0.8.rc1` )

- (Jupyter Kernel) (http://stackoverflow.com/questions/28831854/how-do-i-add-python3-kernel-to-jupyter-ipython)

**reference**:   
[1] [Seasonal ARIMA with Python](http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/)  
[2] [A Complete Tutorial on Time Series Modeling in R](https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/)  
[3] [A comprehensive beginnerâ€™s guide to create a Time Series Forecast (with Codes in Python)](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)  
[4] [ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ìŠ¤ì¿¨/ ì‹œê³„ì—´ ë¶„ì„](https://www.datascienceschool.net/view-notebook/e0c935b3f55c4302b0fb0c93986562cd/)  
[5] [ì‹œê³„ì—´ ë°ì´í„°ì˜ í†µê³„ì  ë¶„ì„ ë°©ë²•](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjJkr3qqvDQAhVIyLwKHUgSDKoQFgggMAA&url=https%3A%2F%2Fbigdata.kookmin.ac.kr%2F%3Fmodule%3Dfile%26act%3DprocFileDownload%26file_srl%3D351%26sid%3D43ea21693d9f550e5e39869d5ce52adc&usg=AFQjCNFeXfnfSgzHQHDP85VZTBUvi4wy0Q&sig2=uZvEKrxxd_rr4Gv4lOB7Yw)




## 1. ì‹œê³„ì—´ ë°ì´í„° ì´í•´

ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„°ì˜ ìš”ì†Œ ë° ì •ìƒ/ë¹„ì •ìƒ ê³¼ì •ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤.

![](figure/TS_pattern.png)
*(ì¶œì²˜: [5])*

### 1.1. ì‹œê³„ì—´ ë°ì´í„° ìš”ì†Œ

- **ì¶”ì„¸(Trend)**: ì¥ê¸°ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë³€ë™ íŒ¨í„´
- **ê³„ì ˆì„±(Seasonal)**: ì£¼,ì›”,ë¶„ê¸°,ë°˜ê¸° ë‹¨ìœ„ ë“± ì´ë¯¸ ì•Œë ¤ì§„ ì‹œê°„ì˜ ì£¼ê¸°ë¡œ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´
- **ì£¼ê¸°(Cyclic)**: ìµœì†Œ 2 ë…„ ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ê³ ì •ëœ ê¸°ê°„ì´ ì•„ë‹Œ ì¥ê¸°ì ì¸ ë³€ë™
- **ëœë¤ìš”ì†Œ (random/residual/remainder)**

![](https://anomaly.io/wp-content/uploads/2015/12/time-series-decomposition-seasonal-trend.png)

![](https://anomaly.io/wp-content/uploads/2015/12/multiplicative-decompose.png)



### 1.2. ì •ìƒ ë° ë¹„ì •ìƒ ê³¼ì • ëª¨í˜• Staionary & Non-Stationary


ì¼ë°˜ì ìœ¼ë¡œ ì‹œê³„ì—´ ë¶„ì„ì˜ ìš©ì´ì„±ì„ ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ ë¹„ì •ìƒê³¼ì • ëª¨í˜•(ğ‘Œ )ì— ë”°ë¥´ëŠ” ì‹œê³„ì—´ ë°ì´í„° "
ë˜í•œ ì¶”ì • ê°€ëŠ¥í•œ ê²°ì •ë¡ ì  ì¶”ì„¸í•¨ìˆ˜ ($ğ‘“_{t}$ , trend) ì™€ í™•ë¥  ì •ìƒê³¼ì •($ ğ‘‹_{t} $)ì˜ í•©ìœ¼ë¡œ ê°€ì •í•˜ê³  ë¶„ì„í•œë‹¤.

$$\begin{align*} & y_{t}\sim f_{\left( t\right) }+X_{t}\end{align*} $$

ë”°ë¼ì„œ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì—ì„œ ì •ìƒê³¼ì • ëª¨í˜•ì˜ íŠ¹ì„± ë° ë¶„ì„ë°©ë²•ë“¤ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ìš°ì„ ì ìœ¼ë¡œ ìš”êµ¬ëœë‹¤. ë‹¤ìŒì€ ì •ìƒ ì‹œê³„ì—´ ëª¨í˜•ê³¼ ë¹„ì •ìƒ ì‹œê³„ì—´ ëª¨í˜•ì˜ íŠ¹ì§• ë¹„êµì´ë‹¤.

[ìƒì„¸ì„¤ëª… ì°¸ê³ ](https://www.datascienceschool.net/view-notebook/0ddd47967585403ab8b4cb60d0e420f6/)

** i.ì‹œê°„ ì¶”ì´ì— ë”°ë¥¸ í‰ê· ê°’ì˜ ë¶ˆë³€ì—¬ë¶€**  
ì •ìƒê³¼ì • - í‰ê· ì€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” í•¨ìˆ˜ê°€ ì•„ë‹ˆë‹¤.;ì¼ì •í•œ í‰ê·  else ë¹„ì •ìƒê³¼ì •

$$ E(y_{t}) = \mu $$

![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Mean_nonstationary.png)

** ii.ì‹œê°„ì¶”ì´ì— ë”°ë¥¸ ë¶„ì‚°ì˜ ë¶ˆë³€ì—¬ë¶€**  
ì •ìƒê³¼ì • - ë¶„ì‚°ì€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” í•¨ìˆ˜ê°€ ì•„ë‹ˆë‹¤.;ì¼ì •í•œ ë¶„ì‚°  else ë¹„ì •ìƒê³¼ì •

$$ var(y_{t}) = \sigma^{2} $$


![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Var_nonstationary.png)

**C.ì‹œì ê°„ì˜ ê³µë¶„ì‚°**  
ê³µë¶„ì‚°ì€ tê°€ ì•„ë‹Œ sì— ì˜ì¡´í•¨
$$ cov(y_{t}, y_{t+s}) = cov(y_{t}, y_{t-s}) = \gamma_{s} $$
$$ cov(X,Y) = E((X-\mu)(Y-\upsilon))  $$

![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Cov_nonstationary.png)


ë³¸ ì¥ì—ì„œ ì†Œê°œí•˜ëŠ” í†µê³„ì  ì‹œê³„ì—´ ì¶”ì • ëª¨í˜•ë“¤ì€ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì •ìƒí™”ì‹œí‚¨ ëª¨í˜• ìœ„ì—ì„œ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, í•„ìˆ˜ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì •ìƒí™” ì‹œí‚¤ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.  

## 2. ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ Framework

ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì„ ì§„í–‰í•œë‹¤.  
![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/flowchart.png)

ë˜ëŠ” [ë§í¬: í™•ë¥  ê³¼ì • ëª¨í˜•ì„ ì¶”ì •í•˜ëŠ” ë°©ë²•](https://www.datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/)ì™€ ê°™ì€ ì ˆì°¨ë¥¼ í†µí•´ í™•ë¥ ëª¨í˜•ì„ ì¶”ì •í•  ìˆ˜ ìˆë‹¤.

### 2.0 Pandas ê¸°ì´ˆ

ë³¸ ì ˆì€ [6]Python for Finance ì˜ ë‚´ìš©ì„ ê¸°ì´ˆë¡œ í•¨.  

[ì°¸ê³ : pandas cheat sheet](https://s3.amazonaws.com/quandl-static-content/Documents/Quandl+-+Pandas,+SciPy,+NumPy+Cheat+Sheet.pdf)



```python
%matplotlib inline
```


```python
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
```


```python
# create a vector with random numbers
a = np.random.standard_normal((9,4))
print ('>>> a=\n',a.round(6))

# create dataframe
fun_df = pd.DataFrame(a)
print ('>>> fun_df=\n',fun_df)

# create DatetimeIndex objects
dates = pd.date_range('2016-1-1',periods=9,freq='M')
print ('>>> dates=\n',dates)

# set index of df with 'dates'
fun_df.index = dates
print ('>>> fun_df.index=\n',fun_df)
```

    >>> a=
     [[-1.293818  0.272272  0.018758 -0.330164]
     [-0.148685 -0.271431  1.00961   1.913422]
     [ 1.948358  1.06523   2.056629 -0.800756]
     [-0.292714 -0.86246  -0.679134  2.018199]
     [ 1.029699  0.038898  2.516392 -0.033658]
     [ 1.403878 -0.577693 -0.992217 -0.834543]
     [-0.006407  0.632325  1.326125  1.069603]
     [ 1.205666  0.051079  0.494714 -0.014192]
     [-2.080606  0.98777   1.64998  -1.058814]]
    >>> fun_df=
               0         1         2         3
    0 -1.293818  0.272272  0.018758 -0.330164
    1 -0.148685 -0.271431  1.009610  1.913422
    2  1.948358  1.065230  2.056629 -0.800756
    3 -0.292714 -0.862460 -0.679134  2.018199
    4  1.029699  0.038898  2.516392 -0.033658
    5  1.403878 -0.577693 -0.992217 -0.834543
    6 -0.006407  0.632325  1.326125  1.069603
    7  1.205666  0.051079  0.494714 -0.014192
    8 -2.080606  0.987770  1.649980 -1.058814
    >>> dates=
     DatetimeIndex(['2016-01-31', '2016-02-29', '2016-03-31', '2016-04-30',
                   '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31',
                   '2016-09-30'],
                  dtype='datetime64[ns]', freq='M')
    >>> fun_df.index=
                        0         1         2         3
    2016-01-31 -1.293818  0.272272  0.018758 -0.330164
    2016-02-29 -0.148685 -0.271431  1.009610  1.913422
    2016-03-31  1.948358  1.065230  2.056629 -0.800756
    2016-04-30 -0.292714 -0.862460 -0.679134  2.018199
    2016-05-31  1.029699  0.038898  2.516392 -0.033658
    2016-06-30  1.403878 -0.577693 -0.992217 -0.834543
    2016-07-31 -0.006407  0.632325  1.326125  1.069603
    2016-08-31  1.205666  0.051079  0.494714 -0.014192
    2016-09-30 -2.080606  0.987770  1.649980 -1.058814


** Basic methods: **


```python
# index values
fun_df.index

# columns
fun_df.columns

# select via index
fun_df.ix['2016-02-29']
fun_df.ix[fun_df.index[1:3]]
fun_df[1:3]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-02-29</th>
      <td>-0.148685</td>
      <td>-0.271431</td>
      <td>1.009610</td>
      <td>1.913422</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1.948358</td>
      <td>1.065230</td>
      <td>2.056629</td>
      <td>-0.800756</td>
    </tr>
  </tbody>
</table>
</div>



** LAMBDA func, apply()** - [lambda - ì°¸ê³ ](https://wikidocs.net/64), [apply - ì°¸ê³ ](http://chrisalbon.com/python/pandas_apply_operations_to_dataframes.html)

![](http://nbviewer.jupyter.org/github/h3imdallr/TIL-datascience/blob/master/ipynb_gitHub/images/non-builtin.png)


```python
# apply()
fun_df.apply(lambda x: x**2)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-01-31</th>
      <td>1.673966</td>
      <td>0.074132</td>
      <td>0.000352</td>
      <td>0.109008</td>
    </tr>
    <tr>
      <th>2016-02-29</th>
      <td>0.022107</td>
      <td>0.073675</td>
      <td>1.019312</td>
      <td>3.661183</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>3.796097</td>
      <td>1.134715</td>
      <td>4.229723</td>
      <td>0.641210</td>
    </tr>
    <tr>
      <th>2016-04-30</th>
      <td>0.085681</td>
      <td>0.743837</td>
      <td>0.461223</td>
      <td>4.073126</td>
    </tr>
    <tr>
      <th>2016-05-31</th>
      <td>1.060280</td>
      <td>0.001513</td>
      <td>6.332228</td>
      <td>0.001133</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1.970874</td>
      <td>0.333730</td>
      <td>0.984494</td>
      <td>0.696463</td>
    </tr>
    <tr>
      <th>2016-07-31</th>
      <td>0.000041</td>
      <td>0.399834</td>
      <td>1.758607</td>
      <td>1.144051</td>
    </tr>
    <tr>
      <th>2016-08-31</th>
      <td>1.453630</td>
      <td>0.002609</td>
      <td>0.244742</td>
      <td>0.000201</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>4.328922</td>
      <td>0.975689</td>
      <td>2.722433</td>
      <td>1.121087</td>
    </tr>
  </tbody>
</table>
</div>




```python
# insert another column (dimension expansion)
fun_df['new'] = np.zeros(9)
fun_df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>new</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-01-31</th>
      <td>-1.293818</td>
      <td>0.272272</td>
      <td>0.018758</td>
      <td>-0.330164</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-02-29</th>
      <td>-0.148685</td>
      <td>-0.271431</td>
      <td>1.009610</td>
      <td>1.913422</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1.948358</td>
      <td>1.065230</td>
      <td>2.056629</td>
      <td>-0.800756</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-04-30</th>
      <td>-0.292714</td>
      <td>-0.862460</td>
      <td>-0.679134</td>
      <td>2.018199</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-05-31</th>
      <td>1.029699</td>
      <td>0.038898</td>
      <td>2.516392</td>
      <td>-0.033658</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1.403878</td>
      <td>-0.577693</td>
      <td>-0.992217</td>
      <td>-0.834543</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-07-31</th>
      <td>-0.006407</td>
      <td>0.632325</td>
      <td>1.326125</td>
      <td>1.069603</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-08-31</th>
      <td>1.205666</td>
      <td>0.051079</td>
      <td>0.494714</td>
      <td>-0.014192</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>-2.080606</td>
      <td>0.987770</td>
      <td>1.649980</td>
      <td>-1.058814</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
fun_df.columns = ['A','B','C','D','E']

# sum
fun_df.sum()
fun_df.cumsum()

# mean
fun_df.mean()

# std
fun_df.std()

# numpy universal functions
np.sqrt(fun_df)

# general stats
fun_df.describe()
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:14: RuntimeWarning: invalid value encountered in sqrt





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.196152</td>
      <td>0.148443</td>
      <td>0.822317</td>
      <td>0.214344</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.325015</td>
      <td>0.665340</td>
      <td>1.207646</td>
      <td>1.174413</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.080606</td>
      <td>-0.862460</td>
      <td>-0.992217</td>
      <td>-1.058814</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-0.292714</td>
      <td>-0.271431</td>
      <td>0.018758</td>
      <td>-0.800756</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.006407</td>
      <td>0.051079</td>
      <td>1.009610</td>
      <td>-0.033658</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.205666</td>
      <td>0.632325</td>
      <td>1.649980</td>
      <td>1.069603</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.948358</td>
      <td>1.065230</td>
      <td>2.516392</td>
      <td>2.018199</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
fun_df.plot()
# plt.plot(fun_df)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x10e133828>




![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_14_1.png)


** Groupby Operations **  

SQLì˜ group select , ì—‘ì…€ì˜ pivot tableê³¼ ë¹„ìŠ·í•œ ê¸°ëŠ¥


```python
fun_df['Quarter'] = ['Q1','Q1','Q1','Q2','Q2','Q2','Q3','Q3','Q3']
fun_df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
      <th>Quarter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-01-31</th>
      <td>-1.293818</td>
      <td>0.272272</td>
      <td>0.018758</td>
      <td>-0.330164</td>
      <td>0.0</td>
      <td>Q1</td>
    </tr>
    <tr>
      <th>2016-02-29</th>
      <td>-0.148685</td>
      <td>-0.271431</td>
      <td>1.009610</td>
      <td>1.913422</td>
      <td>0.0</td>
      <td>Q1</td>
    </tr>
    <tr>
      <th>2016-03-31</th>
      <td>1.948358</td>
      <td>1.065230</td>
      <td>2.056629</td>
      <td>-0.800756</td>
      <td>0.0</td>
      <td>Q1</td>
    </tr>
    <tr>
      <th>2016-04-30</th>
      <td>-0.292714</td>
      <td>-0.862460</td>
      <td>-0.679134</td>
      <td>2.018199</td>
      <td>0.0</td>
      <td>Q2</td>
    </tr>
    <tr>
      <th>2016-05-31</th>
      <td>1.029699</td>
      <td>0.038898</td>
      <td>2.516392</td>
      <td>-0.033658</td>
      <td>0.0</td>
      <td>Q2</td>
    </tr>
    <tr>
      <th>2016-06-30</th>
      <td>1.403878</td>
      <td>-0.577693</td>
      <td>-0.992217</td>
      <td>-0.834543</td>
      <td>0.0</td>
      <td>Q2</td>
    </tr>
    <tr>
      <th>2016-07-31</th>
      <td>-0.006407</td>
      <td>0.632325</td>
      <td>1.326125</td>
      <td>1.069603</td>
      <td>0.0</td>
      <td>Q3</td>
    </tr>
    <tr>
      <th>2016-08-31</th>
      <td>1.205666</td>
      <td>0.051079</td>
      <td>0.494714</td>
      <td>-0.014192</td>
      <td>0.0</td>
      <td>Q3</td>
    </tr>
    <tr>
      <th>2016-09-30</th>
      <td>-2.080606</td>
      <td>0.987770</td>
      <td>1.649980</td>
      <td>-1.058814</td>
      <td>0.0</td>
      <td>Q3</td>
    </tr>
  </tbody>
</table>
</div>




```python
groups = fun_df.groupby('Quarter')
groups #groupby ê°ì²´ì„
```




    <pandas.core.groupby.DataFrameGroupBy object at 0x110de7470>




```python
groups.mean()
groups.max()
groups.size()
```




    Quarter
    Q1    3
    Q2    3
    Q3    3
    dtype: int64



ë‘ê°œì˜ ì—´ì„ ë™ì‹œì— ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” ê·¸ë£¹ ì§€ì •ë„ ê°€ëŠ¥


```python
fun_df['Odd_Even'] = ['Odd','Even','Odd','Even','Odd','Even','Odd','Even','Odd']
groups = fun_df.groupby(['Quarter','Odd_Even'])
groups.size()
groups.mean()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
    </tr>
    <tr>
      <th>Quarter</th>
      <th>Odd_Even</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">Q1</th>
      <th>Even</th>
      <td>-0.148685</td>
      <td>-0.271431</td>
      <td>1.009610</td>
      <td>1.913422</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Odd</th>
      <td>0.327270</td>
      <td>0.668751</td>
      <td>1.037693</td>
      <td>-0.565460</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Q2</th>
      <th>Even</th>
      <td>0.555582</td>
      <td>-0.720077</td>
      <td>-0.835676</td>
      <td>0.591828</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Odd</th>
      <td>1.029699</td>
      <td>0.038898</td>
      <td>2.516392</td>
      <td>-0.033658</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Q3</th>
      <th>Even</th>
      <td>1.205666</td>
      <td>0.051079</td>
      <td>0.494714</td>
      <td>-0.014192</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Odd</th>
      <td>-1.043507</td>
      <td>0.810047</td>
      <td>1.488052</td>
      <td>0.005395</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



### 2.1 EDA; ì‹œê³„ì—´ ë°ì´í„° í™•ì¸í•˜ê¸°


```python
import datetime
from dateutil.relativedelta import relativedelta

import statsmodels
import statsmodels.api as sm  
from statsmodels.tsa.stattools import acf  
from statsmodels.tsa.stattools import pacf
from statsmodels.tsa.seasonal import seasonal_decompose
```

* __Wrangling__:
dropna, column name, DF slicing, date_range, type conversion


```python
df = pd.read_csv('data/portland-oregon-average-monthly.csv', index_col='Month')

#preprocessing
df.dropna(axis=0, inplace=True)
df.columns = ['ridership']
print (df.head(),'\n ... \n', df.tail() )

df = df.ix[:-1]
print (df.tail())
```

            ridership
    Month            
    1960-01       648
    1960-02       646
    1960-03       639
    1960-04       654
    1960-05       630
     ...
                                                        ridership
    Month                                                       
    1969-03                                                 1419
    1969-04                                                 1432
    1969-05                                                 1394
    1969-06                                                 1327
    Portland Oregon average monthly bus ridership (...     n=114
            ridership
    Month            
    1969-02      1425
    1969-03      1419
    1969-04      1432
    1969-05      1394
    1969-06      1327



```python
#ERROR --> index type should be 'datetime'
# df.plot()
```

* change df.index as datetime object:


```python
# OPTION(1): to_datetime()
df.index = pd.to_datetime(df.index)
type(df.index); print(df.head(),'\n ... \n',df.tail())
```

               ridership
    Month               
    1960-01-01       648
    1960-02-01       646
    1960-03-01       639
    1960-04-01       654
    1960-05-01       630
     ...
                ridership
    Month               
    1969-02-01      1425
    1969-03-01      1419
    1969-04-01      1432
    1969-05-01      1394
    1969-06-01      1327



```python
# OPTION(2): date_range()
df.index = pd.date_range("1960-01","1969-06",freq="MS")
type(df.index); print(df.head(),'\n ... \n',df.tail())
```

               ridership
    1960-01-01       648
    1960-02-01       646
    1960-03-01       639
    1960-04-01       654
    1960-05-01       630
     ...
                ridership
    1969-02-01      1425
    1969-03-01      1419
    1969-04-01      1432
    1969-05-01      1394
    1969-06-01      1327



```python
# DF time slicing with datetime
time_window_l = datetime.datetime(1960, 3,1)
time_window_r = datetime.datetime(1961, 7,1)

temp_df = df[
    (df.index >= time_window_l)
    & (df.index <= time_window_r)]
# print (temp_df)

temp_df = df[:time_window_l]
# print (temp_df)
```

* change type of dataframe's column


```python
df['ridership'] = df['ridership'].astype(int)
print (df.dtypes)
# OR, alternatively,
# df['ridership'] = df['ridership'].apply(lambda x: int(x))
# df.dtypes
```

    ridership    int64
    dtype: object



```python
df.plot()
# df.plot(figsize=(12,8), title = 'Montly Ridership', fontsize=14)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x11183b588>




![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_32_1.png)


#### Seasonal Decomposition (STL)

ë‚¨ì€ residual valueë¥¼ ì¶”ì¶œí•¨ìœ¼ë¡œì¨, time-independentí•œ time-seriesë¥¼ ë½‘ìŒ


```python
decomposition = seasonal_decompose(df['ridership'], freq=12)  
fig = plt.figure()  
fig = decomposition.plot()
```


    <matplotlib.figure.Figure at 0x1118fe198>



![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_34_1.png)


Seasonal Trend Decomposition (STL) í™œìš©:
- Anomaly Deteciton (residualí™œìš©)
- Stationarize
- ì‹œê³„ì—´ íŒ¨í„´ ë¹„êµ (ì˜ˆì‹œ, ì•„ë˜)

![](figure/STL_example.png)

### 2.2 ì‹œê³„ì—´ ë°ì´í„° ì •ìƒí™” í•˜ê¸°

### ì •ìƒì„± í™•ì¸ stationarity check
ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„°ê°€ stationaryí•œ ê²½ìš°ëŠ” ê±°ì˜ ì—†ìŒ.
ì •ìƒì„±ì„ Testí•˜ê¸° ìœ„í•´ì„œ ë‘ê°€ì§€ ë°©ë²• ì‚¬ìš©   

**(1) ëˆˆìœ¼ë¡œ ì§ê´€ì  í™•ì¸ ~ STL, Rolling statistics(moving average)    
(2) Dickey-FUller test [ë§í¬](https://www.datascienceschool.net/view-notebook/ebb638fc880145b9adeef8dfa630f067/)  **

ì•„ë˜ëŠ”  Dickey-Fuller test ì™€ ë”ë¶ˆì–´  trendë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì¤‘ í•˜ë‚˜ì¸ rolling statisticsë¥¼ ì´ìš©í•´ì„œ ë™ì‹œì— ì •ìƒì„±ì„ ê²€ì‚¬í•˜ëŠ” ë°©ë²•ì´ë‹¤


```python
from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):

    #Determing rolling statistics
    rolmean = pd.rolling_mean(timeseries, window=12)
    rolstd = pd.rolling_std(timeseries, window=12)

    #Plot rolling statistics:
    fig = plt.figure(figsize=(10, 6))
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')

    plt.legend(loc='best'); plt.title('Rolling Mean & Standard Deviation')
    plt.show()

    #Perform Dickey-Fuller test:
    print ('<Results of Dickey-Fuller Test>')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4],
                         index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print (dfoutput)
```


```python
test_stationarity(df['ridership'])
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).mean()
    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).std()



![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_38_1.png)


    <Results of Dickey-Fuller Test>
    Test Statistic                  -1.536597
    p-value                          0.515336
    #Lags Used                      12.000000
    Number of Observations Used    101.000000
    Critical Value (1%)             -3.496818
    Critical Value (5%)             -2.890611
    Critical Value (10%)            -2.582277
    dtype: float64


* Judgment:   
(null-hypothesis: TS is non-stationary)  
p-value < 0.05: reject null-hypothesis --> Stationary  
p-value > 0.05: accept --> non-Stationary  

### ì •ìƒí™” Stationarize

ë¹„ì •ìƒ í™•ë¥ ê³¼ì •ì„ ì •ìƒ í™•ë¥  ê³¼ì •ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ [[1]](http://people.duke.edu/~rnau/whatuse.htm), [[2]](https://www.datascienceschool.net/view-notebook/3f485c426a4b49fc9de95a02137ca6b4/)ê°€ ìˆìœ¼ë©°, ì£¼ì–´ì§„ ë°ì´í„°ì— ë”°ë¼ ê°€ì¥ íš¨ìœ¨ì ì¸ ë°©ë²•ì´ ë‹¤ë¥´ê±°ë‚˜ í˜¼í•©í•˜ì—¬ ì‚¬ìš©í•œë‹¤. (ìƒì„¸ë‚´ìš© ë§í¬ì°¸ì¡°)
ì—¬ê¸°ì„œëŠ” ì§§ê²Œ ì„¸ê°€ì§€ì— ëŒ€í•´ì„œ ì†Œê°œí•œë‹¤.
- **ì°¨ë¶„(differencing)**: 1ì°¨ì°¨ë¶„. Trend ì œê±°í•˜ëŠ”ë° ìš©ì´ $\Delta y_{t} = y_{t} - y_{t-1}$
- **ë¡œê·¸ë³€í™˜(lograithm)**: í‘œì¤€í¸ì°¨ê°€ ìë£Œì˜ í¬ê¸°ì— ë¹„ë¡€í•˜ì—¬ ì¦ê°€í• ë•Œ
- **Box-Cox ë³€í™˜**: ì •ê·œë¶„í¬ê°€ ì•„ë‹Œ ìë£Œë¥¼ ì •ê·œë¶„í¬ë¡œ ë³€í™˜.


ì—¬ê¸°ì„œëŠ” ì°¨ë¶„ì„ ì´ìš©í•˜ì—¬ ì •ìƒí™”ë¥¼ í•œë‹¤.




```python
df['first_difference'] = df['ridership'] - df['ridership'].shift(1)  
# Or Alternatively,
# df.diff().plot()
test_stationarity(df.first_difference.dropna(inplace=False))
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).mean()
    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).std()



![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_41_1.png)


    <Results of Dickey-Fuller Test>
    Test Statistic                  -1.938696
    p-value                          0.314082
    #Lags Used                      11.000000
    Number of Observations Used    101.000000
    Critical Value (1%)             -3.496818
    Critical Value (5%)             -2.890611
    Critical Value (10%)            -2.582277
    dtype: float64


ì¢€ë” ë‚˜ì€ ìˆ˜ì¤€ì˜ ì •ìƒí™”ë¥¼ ìœ„í•´, ë„í•œ seasonal íŒ¨í„´ì„ ì¢€ë” ëª…í™•íˆ ë³´ê³  ì‹¶ê³ , long-termì—ì„œë„ ì˜ ë‚¨ì•„ìˆê²Œ í•˜ê¸° ìœ„í•´ì„œ seasonaly differencing ì„ ì ìš©í•œë‹¤.


```python
df['seasonal_first_difference'] = df['first_difference'] - df['first_difference'].shift(12)  
test_stationarity(df.seasonal_first_difference.dropna(inplace=False))

# Else:
# df['log_first_difference'] = df.riders_log - df.riders_log.shift(1)
# df['seasonal_difference'] = df.riders - df.riders.shift(12)  
# df['log_seasonal_difference'] = df.riders_log - df.riders_log.shift(12)
# df['log_seasonal_first_difference'] = df.log_first_difference - df.log_first_difference.shift(12)
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).mean()
    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with
    	Series.rolling(center=False,window=12).std()



![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_43_1.png)


    <Results of Dickey-Fuller Test>
    Test Statistic                -9.258520e+00
    p-value                        1.427874e-15
    #Lags Used                     0.000000e+00
    Number of Observations Used    1.000000e+02
    Critical Value (1%)           -3.497501e+00
    Critical Value (5%)           -2.890906e+00
    Critical Value (10%)          -2.582435e+00
    dtype: float64


p-valueê°€ ë” ë†’ì•„ì§„ ì ì—ì„œ seasonal first differenceë¥¼ í†µí•´ ìµœì¢…ì ìœ¼ë¡œ dataë¥¼ ì •ìƒí™” ì‹œì¼°ë‹¤ê³  íŒë‹¨í•œë‹¤.ì¶”ê°€ì ìœ¼ë¡œ ë¡œê·¸ë³€í™˜(`df[~] = np.log(df[~])`)ë„ í•  ìˆ˜ ìˆìœ¼ë‚˜, ë³¸ ê²½ìš°ì—ì„œëŠ” ë¶„ì„í›„ í¬ê²Œ ë‚˜ì•„ì§€ì§€ ì•Šì•˜ë‹¤.
ë˜í•œ ì¶”ê°€ë¡œ ì¶”ì„¸ë¥¼ ì¶”ì •í•˜ì—¬ ì œê±°í•˜ëŠ” ê¸°ë²•[(ë§í¬: ê²°ì •ë¡ ì  ì¶”ì„¸/ë‹¤í•­ì‹ ì¶”ì„¸/ ê³„ì ˆì„± ì¶”ì„¸ ì¶”ì •)](https://www.datascienceschool.net/view-notebook/240b62a8927043c79b5384536e42f99d/)ë“¤ì´ ìˆìœ¼ë‚˜, ì¶©ë¶„íˆ ì •ìƒí™” ë˜ì—ˆë‹¤ê³  íŒë‹¨í•˜ê³  ë³¸ ë¶„ì„ì—ì„œëŠ” ì†Œê°œí•˜ì§€ ì•ŠëŠ”ë‹¤.

 ### 2.3 ëª¨ìˆ˜ì¶”ì •;  ìµœì  íŒŒë¼ë¯¸í„°(ëª¨í˜•ì°¨ìˆ˜) ë„ì¶œ

### ARIMA ëª¨ë¸ì˜ ê°œë…

- ì¶œì²˜: [ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ìŠ¤ì¿¨](https://www.datascienceschool.net/view-notebook/d5226389a8414583a45fb47e1e1cf6fb/)

** a. ì •ìƒê³¼ì • í™•ë¥  ëª¨í˜•(1/2) - General Linear Process Model **  
ì •ìƒí™•ë¥  ê³¼ì •ì—ì„œ ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨í˜•ì€ ì¼ë°˜ì„ í˜• í™•ë¥  ê³¼ì • ëª¨í˜•(General Linear Process Model)ì´ë‹¤. í•´ë‹¹ ëª¨í˜•ì€ ì‹œê³„ì—´ì´ [ê°€ìš°ì‹œì•ˆ ë°±ìƒ‰ì¡ìŒ](https://www.datascienceschool.net/view-notebook/6b963e771dc54f8c8cb23437274a86d6/) ($e_{t}$)ì˜ í˜„ì¬ê°’ê³¼ ê³¼ê±°ê°’ë“¤ì˜ ì„ í˜•ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤ê³  ê°€ì •. $\psi $ ëŠ” ê°€ì¤‘ê³„ìˆ˜(weight coefficient).

$$ Y_t = e_t + \psi_1 e_{t-1}  + \psi_2 e_{t-2}  + \psi_1 e_{t-3}  + \cdots $$

ìœ„ ëª¨í˜•ì˜ ë¸”ëŸ­ ë‹¤ì´ì–´ê·¸ë¨ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![](figure/glpm.png)

** b. ì •ìƒê³¼ì • í™•ë¥  ëª¨í˜• (2/2) MA, AR, ARMA **

ì¼ë°˜ ì„ í˜• í™•ë¥  ê³¼ì • ëª¨í˜•ì€ ê³„ìˆ˜ì˜ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì€ í•˜ìœ„ ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëœë‹¤.

- **MA (Moving Average) ëª¨í˜•**: ë°±ìƒ‰ ì¡ìŒì˜ í˜„ì¬ ê°’ê³¼ ê³¼ê±° ê°’ ì¤‘ ìœ í•œ(finite)ê°œì˜ ê°’ì— ëŒ€í•œ ì„ í˜• ê°€ì¤‘í•©(linear weighted summation)ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” í™•ë¥  ê³¼ì •.qì°¨ìˆ˜ì— ëŒ€í•´ì„œ MA(q)ë¡œ í‘œê¸°  

$$ Y_t = e_t - \theta_1 e_{t-1}  - \theta_2 e_{t-2} - \cdots - \theta_q e_{t-q} $$
![](figure/ma.png)

- **AR (Auto-Regressive) ëª¨í˜•**: ìê¸° ìì‹ ì˜ ê³¼ê±°ê°’ì— ì˜ì¡´ì ì¸ ëª¨í˜•. ë°±ìƒ‰ ì¡ìŒì˜ í˜„ì¬ê°’ê³¼ ìê¸° ìì‹ ì˜ ê³¼ê±°ê°’ì˜ ì„ í˜• ê°€ì¤‘í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì •ìƒ í™•ë¥  ëª¨í˜•. pì°¨ìˆ˜ì˜ ARëª¨í˜•: AR(p)

$$ Y_t = \phi_1 Y_{t-1}  + \phi_2 Y_{t-2}  + \cdots + \phi_p Y_{t-p}  + e_t $$

![](figure/ar.png)

ì´ ëª¨í˜•ì´ ì„ í˜•í™•ë¥ ê³¼ì •ì„ ë”°ë¥´ëŠ” ê²ƒì€ ì•„ë˜ì™€ ê°™ì´ ì¦ëª… í•  ìˆ˜ ìˆë‹¤.   


$$
\begin{eqnarray}
Y_t
&=& \phi Y_{t-1} + e_t \\
&=& \phi \left( \phi Y_{t-2} + e_{t-1} \right) + e_t \\
&=& \phi^2 Y_{t-2} + \phi e_{t-1} + e_t \\
&=& \phi^2  \left( \phi Y_{t-3} + e_{t-2} \right)  + \phi e_{t-1} + e_t \\
&=& \phi^3 Y_{t-3} + \phi^2 e_{t-2}  + \phi e_{t-1} + e_t \\
&\vdots& \\
&=& e_t + \phi e_{t-1} + \phi^2 e_{t-2} + \phi^3 e_{t-3} + \cdots  \\
\end{eqnarray}
$$

- **ARMA (Auto-Regressive Moving Average) ëª¨í˜•**: ARMA(p,q) ëª¨í˜•ì€ AR(p) ëª¨í˜•ê³¼ MA(q) ëª¨í˜•ì˜ íŠ¹ì§•ì„ ëª¨ë‘ ê°€ì§€ëŠ” ëª¨í˜•ì„ ë§í•¨.  

$$ Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \cdots + \phi_p Y_{t-p} + e_t - \theta_1 e_{t-1} - \theta_2 e_{t-2} \cdots  - \theta_q e_{t-q} $$


** c. ë¹„ì •ìƒê³¼ì •í™•ë¥ ëª¨í˜• -  ARIMA **

 ë¹„ì •ìƒ ê³¼ì • ëª¨í˜• ì¤‘ ê°€ì¥ ëŒ€í‘œì ì¸ ëª¨í˜•ìœ¼ë¡œ,  ARMA ëª¨í˜•ì„ ëˆ„ì í•œ ëª¨í˜•ì´ë‹¤. ì‹œê³„ì—´  $Y_{t}$ ì„ ì°¨ë¶„í•œ ê²°ê³¼ë¡œ ë§Œë“¤ì–´ì§„ ì‹œê³„ì—´ $\nabla Y_t = Y_t - Y_{t-1}$  ì´ ARMA ëª¨í˜•ì„ ë”°ë¥´ë©´ ì›ë˜ì˜ ì‹œê³„ì—´ $Y_{t}$ ë¥¼ ARIMA(Autoregressive Integrated Moving Average) ëª¨í˜•ì´ë¼ê³  í•œë‹¤.

ë§Œì•½  $d$ ë²ˆ ì°¨ë¶„í•œ í›„ì—ì•¼ ì‹œê³„ì—´  $\nabla Y_t$ ê°€ ARMA(p,q) ëª¨í˜•ì„ ë”°ë¥¸ë‹¤ë©´ ì ë¶„ ì°¨ìˆ˜(order of integration)ê°€  $d$ ì¸ ARIMA ëª¨í˜•ìœ¼ë¡œ ARIMA(p, d, q)ë¡œ í‘œê¸°í•œë‹¤.  $q=0$ ì¸ ê²½ìš°ì—ëŠ” ARI(p,d), $p=0$ ì¸ ê²½ìš°ì—ëŠ” IMA(d,q)ë¡œ í‘œê¸°í•œë‹¤.


### ARIMA ëª¨í˜• ì°¨ìˆ˜ ê²°ì •  

ì•ì„œ ì„¤ëª…í•œ ARIMAì˜ p, d, q ëª¨í˜•ì°¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ê²°ì • í•  ìˆ˜ ìˆë‹¤. [(ìƒì„¸ì°¸ì¡°)](https://www.datascienceschool.net/view-notebook/b39ccd2da3e64d6e91981e23e01816c4/)

- **Augmented Dickey-Fuller ê²€ì •** : d
- **ìê¸°ìƒê´€ê³„ìˆ˜ í•¨ìˆ˜(ACF)**: q
- **í¸ìê¸°ìƒê´€ê³„ìˆ˜ í•¨ìˆ˜(PACF)** : p

| ëª¨í˜•        | ACF  | PACF  |
| :-------: |:-------------:| :-------------:|
| AR(p)| ì§€ìˆ˜í•¨ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ê±°ë‚˜ ì ì°¨ ì§„í­ì´ ì¶•ì†Œë˜ëŠ” ì‚¬ì¸ ê³¡ì„ ì˜ íŒŒë™ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ë˜ëŠ” ì–‘ìª½ëª¨ë‘ ë‚˜íƒ€ë‚¨ (ì‹œì°¨ê°€ ì¦ê°€í•¨ì— ë”°ë¼0 ìœ¼ë¡œ ê¸‰ì†íˆ ì ‘ê·¼) |p ì˜ ì‹œì°¨ê¹Œì§€ ìœ ì˜ì„± ìˆëŠ” ê°’ì„ ë‚˜íƒ€ë‚´ê³  ì´í›„ ì†Œë©¸í•¨|
| MA(q)| q ì˜ ì‹œì°¨ê¹Œì§€ ìœ ì˜ì„± ìˆëŠ” ê°’ì„ ë‚˜íƒ€ë‚´ê³  ì´í›„ ì†Œë©¸í•¨ | ì§€ìˆ˜í•¨ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ê±°ë‚˜ ì ì°¨ì§„í­ì´ ì¶•ì†Œë˜ëŠ” ì‚¬ì¸ ê³¡ì„ ì˜ íŒŒë™ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ë˜ëŠ” ì–‘ìª½ ëª¨ë‘ ë‚˜íƒ€ë‚¨ (ì‹œì°¨ê°€ ì¦ê°€í•¨ì— ë”°ë¼ 0 ìœ¼ë¡œê¸‰ì†íˆì ‘ê·¼)|
| ARMA(p,q)| ì§€ìˆ˜í•¨ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ê±°ë‚˜ ì ì°¨ ì§„í­ì´ ì¶•ì†Œë˜ëŠ” ì‚¬ì¸ ê³¡ì„ ì˜ íŒŒë™ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ë˜ëŠ” ì–‘ìª½ ëª¨ë‘ ë‚˜íƒ€ë‚¨ (ì‹œì°¨ê°€ ì¦ê°€í•¨ì— ë”°ë¼ 0 ìœ¼ë¡œ ê¸‰ì†íˆ ì ‘ê·¼) | ì§€ìˆ˜í•¨ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ê±°ë‚˜ ì ì°¨ ì§„í­ì´ ì¶•ì†Œë˜ëŠ” ì‚¬ì¸ ê³¡ì„ ì˜ íŒŒë™ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ë˜ëŠ” ì–‘ìª½ ëª¨ë‘ ë‚˜íƒ€ë‚¨ (ì‹œì°¨ê°€ ì¦ê°€í•¨ì— ë”°ë¼ 0 ìœ¼ë¡œ ê¸‰ì†íˆ ì ‘ê·¼) |
![](figure/parameter.png)
![ARIMA](figure/ARIMA.png)


ë³¸ ë¶„ì„ì—ì„œëŠ” ì—°ë‹¨ìœ„(12ê°œì›”) ì°¨ì´ë¡œ ì •ìƒí™” ì‹œì¼œì„œ, Seasonal ARIMA ëª¨ë¸ë¡œ ë¶„ë¥˜ë¨.  
> Seasonal ARIMA ëª¨í˜•ì€ ì¤„ì—¬ì„œ SARIMAë¼ê³  í•˜ê¸°ë„ í•œë‹¤. ë‹¨ìˆœ SARIMA ëª¨í˜•ì€ ê° ê³„ì ˆì— ë”°ë¥¸ ë…ë¦½ì ì¸ ARIMA ëª¨í˜•ì´ í•©ì³ì ¸ ìˆëŠ” ëª¨í˜•ì´ë‹¤. ê¸°ì¡´ ARIMA(p,d,q) ëª¨í˜•ì— ê³„ì ˆì„± ì£¼ê¸°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì°¨ìˆ˜ sê°€ ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— SARIMA(P,D,Q,s) ë¡œ í‘œê¸°í•œë‹¤.  
sì˜ ê°’ì€ ì›”ë³„ ê³„ì ˆì„±ì„ ë‚˜íƒ€ë‚¼ ë•ŒëŠ”  $s=12$ ê°€ ë˜ê³  ë¶„ê¸°ë³„ ê³„ì ˆì„±ì„ ë‚˜íƒ€ë‚¼ ë•ŒëŠ”  $s=4$ ê°€ ëœë‹¤


```python
fig = plt.figure(figsize=(12,8))
ax1 = fig.add_subplot(211)
fig = sm.graphics.tsa.plot_acf(df.seasonal_first_difference.iloc[13:], lags=40, ax=ax1)
ax2 = fig.add_subplot(212)
fig = sm.graphics.tsa.plot_pacf(df.seasonal_first_difference.iloc[13:],lags=40,ax=ax2)
```


![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_48_0.png)


ìœ„ ê·¸ë˜í”„ì—ì„œ, 1ì°¨ ì°¨ë¶„í•œ ê°’(first_diff)ì´ t+1..t+12ê¹Œì§€ AR(0), MR(0), d=1.  

12ë²ˆì§¸ì—ì„œ +->- SAR(1), SMA(1)

ìµœì¢…ì ìœ¼ë¡œ **SARIMA (0,1,0)X(1,1,1,12) **  

SARIMA ëª¨í˜•ì¶”ì • [ì˜ˆì‹œ](https://www.datascienceschool.net/view-notebook/602e62fc1c544ffcb43c2c7e1484dc14/)

### 2.4 ëª¨ë¸ ìˆ˜ë¦½  
ìœ„ ë‹¨ê³„ì—ì„œ í™•ì •í•œ ëª¨ë¸ì˜ ëª¨í˜•ì°¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬, (Seasonal) ARIMA ëª¨ë¸ì„ ìƒì„±í•œë‹¤


```python
mod = sm.tsa.SARIMAX(df['ridership'],order=(0,1,0), seasonal_order=(1,1,1,12))
results = mod.fit()
print (results.summary())

# import statsmodels.api as sm  
# mod = sm.tsa.statespace.SARIMAX(df['ridership'], trend='n', order=(0,1,0), seasonal_order=(0,1,1,12))
# results = mod.fit()
```

                                     Statespace Model Results                                 
    ==========================================================================================
    Dep. Variable:                          ridership   No. Observations:                  114
    Model:             SARIMAX(0, 1, 0)x(1, 1, 1, 12)   Log Likelihood                -501.340
    Date:                            Thu, 22 Dec 2016   AIC                           1008.680
    Time:                                    10:37:58   BIC                           1016.889
    Sample:                                01-01-1960   HQIC                          1012.012
                                         - 06-01-1969                                         
    Covariance Type:                              opg                                         
    ==============================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
    ------------------------------------------------------------------------------
    ar.S.L12       0.3236      0.115      2.816      0.005       0.098       0.549
    ma.S.L12      -0.9990      2.489     -0.401      0.688      -5.878       3.880
    sigma2       984.6913   2426.491      0.406      0.685   -3771.144    5740.527
    ===================================================================================
    Ljung-Box (Q):                       36.56   Jarque-Bera (JB):                 4.81
    Prob(Q):                              0.63   Prob(JB):                         0.09
    Heteroskedasticity (H):               1.48   Skew:                             0.38
    Prob(H) (two-sided):                  0.26   Kurtosis:                         3.75
    ===================================================================================

    Warnings:
    [1] Covariance matrix calculated using the outer product of gradients.


## í‰ê°€
ëª¨í˜•ì´ í›Œë¥­í•˜ë‹¤ë©´ ì´ ê°’ì€ ë”ì´ìƒ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ìš”ì†Œê°€ ì „í˜€ ì—†ëŠ” ì‹œê³„ì—´ ì¦‰, ê°€ìš°ì‹œì•ˆ ë°±ìƒ‰ ì¡ìŒì— ê°€ê¹Œìš´ íŠ¹ì„±ì„ ë³´ì—¬ì•¼ í•œë‹¤.  
ë°±ìƒ‰ì¡ìŒ: ë°±ìƒ‰ ì¡ìŒ  $e$ ì€ í™•ë¥  ê³¼ì •ì„ êµ¬ì„±í•˜ëŠ” ëª¨ë“  ê°œë³„ í™•ë¥  ë³€ìˆ˜  $e_{t}$ ë“¤ì´ ì„œë¡œ ë…ë¦½ì´ê³ (independent) ë™ì¼í•œ í™•ë¥  ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”(identically distributed) í™•ë¥  ê³¼ì •ì„ ë§í•œë‹¤.

ë°±ìƒ‰ ì¡ìŒì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì„±ì„ ë§Œì¡±í•œë‹¤.

- ì •ìƒ ê³¼ì •(stictly stationary process)ì´ë‹¤.

- ì‹œì°¨(lag)ê°€ 0ì¼ ê²½ìš°, ìê¸°ê³µë¶„ì‚°ì€ í™•ë¥  ë¶„í¬ì˜ ë¶„ì‚°ì´ ë˜ê³  ì‹œì°¨ê°€ 0ì´ ì•„ë‹Œ ê²½ìš°, ìê¸°ê³µë¶„ì‚°ì€ 0ì´ë‹¤.  

$$\gamma_l = \begin{cases} \text{Var}[e_t] & \;\; \text{ for } l = 0 \\  0 & \;\; \text{ for }  l \neq 0 \end{cases}$$

- ì‹œì°¨(lag)ê°€ 0ì¼ ê²½ìš°, ìê¸°ìƒê´€ê³„ìˆ˜ëŠ” 1ì´ ë˜ê³  ì‹œì°¨ê°€ 0ì´ ì•„ë‹Œ ê²½ìš°, ìê¸°ìƒê´€ê³„ìˆ˜ëŠ” 0ì´ë‹¤.  

$$\rho_l = \begin{cases} 1 & \;\; \text{ for } l = 0 \\  0 & \;\; \text{ for }  l \neq 0 \end{cases}$$



```python
results.plot_diagnostics();
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0);
```


![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_53_0.png)


### 2.5  ì‹œê³„ì—´ ì˜ˆì¸¡


```python
df['forecast'] = results.predict(start = len(df)-12, end= len(df), dynamic= True)  
df[['ridership', 'forecast']].plot()
df[-12:]
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/statsmodels/base/data.py:551: FutureWarning: TimeSeries is deprecated. Please use Series
      return TimeSeries(squeezed, index=self.predict_dates)





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ridership</th>
      <th>first_difference</th>
      <th>seasonal_first_difference</th>
      <th>forecast</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1968-07-01</th>
      <td>1258</td>
      <td>-79.0</td>
      <td>-7.0</td>
      <td>1296.346206</td>
    </tr>
    <tr>
      <th>1968-08-01</th>
      <td>1214</td>
      <td>-44.0</td>
      <td>11.0</td>
      <td>1258.596774</td>
    </tr>
    <tr>
      <th>1968-09-01</th>
      <td>1326</td>
      <td>112.0</td>
      <td>-19.0</td>
      <td>1356.836145</td>
    </tr>
    <tr>
      <th>1968-10-01</th>
      <td>1417</td>
      <td>91.0</td>
      <td>82.0</td>
      <td>1395.808702</td>
    </tr>
    <tr>
      <th>1968-11-01</th>
      <td>1417</td>
      <td>0.0</td>
      <td>26.0</td>
      <td>1394.657184</td>
    </tr>
    <tr>
      <th>1968-12-01</th>
      <td>1329</td>
      <td>-88.0</td>
      <td>-24.0</td>
      <td>1339.628128</td>
    </tr>
    <tr>
      <th>1969-01-01</th>
      <td>1461</td>
      <td>132.0</td>
      <td>63.0</td>
      <td>1424.051451</td>
    </tr>
    <tr>
      <th>1969-02-01</th>
      <td>1425</td>
      <td>-36.0</td>
      <td>-47.0</td>
      <td>1438.092678</td>
    </tr>
    <tr>
      <th>1969-03-01</th>
      <td>1419</td>
      <td>-6.0</td>
      <td>20.0</td>
      <td>1407.277891</td>
    </tr>
    <tr>
      <th>1969-04-01</th>
      <td>1432</td>
      <td>13.0</td>
      <td>3.0</td>
      <td>1427.492444</td>
    </tr>
    <tr>
      <th>1969-05-01</th>
      <td>1394</td>
      <td>-38.0</td>
      <td>-22.0</td>
      <td>1406.615247</td>
    </tr>
    <tr>
      <th>1969-06-01</th>
      <td>1327</td>
      <td>-67.0</td>
      <td>4.0</td>
      <td>1362.732612</td>
    </tr>
  </tbody>
</table>
</div>




![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_55_2.png)


ì˜ˆì¸¡ ê¸°ê°„ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë¶€ì •í™•í•´ ì§ˆ ìˆ˜ ìˆìŒ (ì•„ë˜, 24ê°œì›”)


```python
df['forecast'] = results.predict(start = len(df)-24, end= len(df), dynamic= True)  
df[['ridership', 'forecast']].plot()
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/statsmodels/base/data.py:551: FutureWarning: TimeSeries is deprecated. Please use Series
      return TimeSeries(squeezed, index=self.predict_dates)





    <matplotlib.axes._subplots.AxesSubplot at 0x112100860>




![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_57_2.png)



```python
start = datetime.datetime.strptime("1969-07-01", "%Y-%m-%d")
# >1982-07-01 00:00:00
date_list = [start + relativedelta(months=x) for x in range(0,12)]
#> 1982/7/1,8/1, ... 1983/6/1

future_df = pd.DataFrame(index=date_list, columns= df.columns)
new_df = pd.concat([df, future_df]) #concatenated  dataframe
# print(new_df.head(),'\n...\n',new_df.tail())
```


```python
new_df['forecast'] = results.predict(start = len(df), end = len(df)+11, dynamic= True)  
new_df[['ridership', 'forecast']].ix[-48:].plot()
```

    /Users/Josh/anaconda/envs/venv_py35/lib/python3.5/site-packages/statsmodels/base/data.py:551: FutureWarning: TimeSeries is deprecated. Please use Series
      return TimeSeries(squeezed, index=self.predict_dates)





    <matplotlib.axes._subplots.AxesSubplot at 0x111b33550>




![png](/figures-h3imdallr/timeseries_forecast_files/timeseries_forecast_59_2.png)



```python
print (df.forecast[-12:])
```

    1968-07-01    1533.437422
    1968-08-01    1507.627276
    1968-09-01    1591.243235
    1968-10-01    1644.424477
    1968-11-01    1661.629774
    1968-12-01    1615.434831
    1969-01-01    1708.999117
    1969-02-01    1730.117397
    1969-03-01    1697.643239
    1969-04-01    1719.164343
    1969-05-01    1693.700319
    1969-06-01    1665.040104
    Freq: MS, Name: forecast, dtype: float64


## Further Study
- [Seasonal ARIMA ë‹¤ë¥¸ ì˜ˆì œ](https://www.datascienceschool.net/view-notebook/8c4f6ad9487149ca872374bbbf098e5f/)
- [ARIMAX](https://www.datascienceschool.net/view-notebook/3e70dc86adb841b58736522c491eb770/)
- [LSTMì„ ì´ìš©í•œ ì‹œê³„ì—´ ì¶”ì •](http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)
- anomaly detection ì˜ˆì œ
- [Bayesian Time Series Forecasting](http://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/)



(End of Doc)
